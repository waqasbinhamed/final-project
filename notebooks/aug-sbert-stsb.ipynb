{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --quiet -U sentence-transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-22T10:02:54.500795Z","iopub.execute_input":"2022-04-22T10:02:54.50106Z","iopub.status.idle":"2022-04-22T10:03:04.817725Z","shell.execute_reply.started":"2022-04-22T10:02:54.501031Z","shell.execute_reply":"2022-04-22T10:03:04.816888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Dowloading split dataset\n! wget https://public.ukp.informatik.tu-darmstadt.de/reimers/sentence-transformers/datasets/quora-IR-dataset.zip\n! unzip ./quora-IR-dataset.zip","metadata":{"execution":{"iopub.status.busy":"2022-04-22T10:03:04.819729Z","iopub.execute_input":"2022-04-22T10:03:04.819982Z","iopub.status.idle":"2022-04-22T10:03:14.997293Z","shell.execute_reply.started":"2022-04-22T10:03:04.819951Z","shell.execute_reply":"2022-04-22T10:03:14.996327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom datetime import datetime\nimport csv\nimport random\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader\nfrom sentence_transformers import models, losses, util\nfrom sentence_transformers import SentenceTransformer, evaluation\nfrom sentence_transformers.readers import InputExample\nfrom transformers import T5ForConditionalGeneration,T5Tokenizer\nfrom sentence_transformers.cross_encoder import CrossEncoder\n\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n\n# setting seed\nrandom.seed(42)\nos.environ['PYTHONHASHSEED'] = str(42)\nnp.random.seed(42)\ntorch.manual_seed(42)\ntorch.cuda.manual_seed(42)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = True","metadata":{"execution":{"iopub.status.busy":"2022-04-22T10:03:14.998914Z","iopub.execute_input":"2022-04-22T10:03:14.999217Z","iopub.status.idle":"2022-04-22T10:03:22.08863Z","shell.execute_reply.started":"2022-04-22T10:03:14.999176Z","shell.execute_reply":"2022-04-22T10:03:22.087836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 5\nbatch_size = 32\nmodel_save_path = 'output/sbert_stsb_10'","metadata":{"execution":{"iopub.status.busy":"2022-04-22T10:03:22.090844Z","iopub.execute_input":"2022-04-22T10:03:22.091092Z","iopub.status.idle":"2022-04-22T10:03:22.095093Z","shell.execute_reply.started":"2022-04-22T10:03:22.09106Z","shell.execute_reply":"2022-04-22T10:03:22.094134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gold_samples = []\nwith open('classification/train_pairs.tsv', encoding='utf8') as fIn:\n    reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_NONE)\n    for row in reader:\n        sample = InputExample(texts=[row['question1'], row['question2']], label=int(row['is_duplicate']))\n        gold_samples.append(sample)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T10:03:22.096375Z","iopub.execute_input":"2022-04-22T10:03:22.096883Z","iopub.status.idle":"2022-04-22T10:03:25.785724Z","shell.execute_reply.started":"2022-04-22T10:03:22.096845Z","shell.execute_reply":"2022-04-22T10:03:25.784955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('./classification/train_pairs.tsv', delimiter='\\t', on_bad_lines='skip')\ndf","metadata":{"execution":{"iopub.status.busy":"2022-04-22T10:03:25.787022Z","iopub.execute_input":"2022-04-22T10:03:25.787261Z","iopub.status.idle":"2022-04-22T10:03:25.791667Z","shell.execute_reply.started":"2022-04-22T10:03:25.787229Z","shell.execute_reply":"2022-04-22T10:03:25.790944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.is_duplicate.groupby(df.is_duplicate).count()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T10:03:25.792933Z","iopub.execute_input":"2022-04-22T10:03:25.79332Z","iopub.status.idle":"2022-04-22T10:03:25.800602Z","shell.execute_reply.started":"2022-04-22T10:03:25.793284Z","shell.execute_reply":"2022-04-22T10:03:25.799869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Paraphrase sentences to generated new dataset using T5 model trained on duplicate questions from the Quora dataset. \n# Pre-trained model available at https://huggingface.co/ramsrigouthamg/t5_paraphraser\n\nnum_sentences = 20000 # number of rows used to generate augmented data\nmax_length = 256 - len(\"paraphrase: \" + \" </s>\")    \n\nmodel_name = 'ramsrigouthamg/t5_paraphraser'\ntorch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\ntokenizer = T5Tokenizer.from_pretrained(model_name)\nmodel = T5ForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n\ndef get_response(input_texts, num_return_sequences=1):\n    encoding = tokenizer.batch_encode_plus(input_texts,pad_to_max_length=True, return_tensors=\"pt\", max_length=256)\n    input_ids, attention_masks = encoding[\"input_ids\"].to(torch_device), encoding[\"attention_mask\"].to(torch_device)\n    beam_outputs = model.generate(\n        input_ids=input_ids, attention_mask=attention_masks,\n        do_sample=True,\n        max_length=max_length,\n        top_k=120,\n        top_p=0.98,\n        early_stopping=True,\n        num_return_sequences=num_return_sequences\n    )\n    tgt_texts = tokenizer.batch_decode(beam_outputs, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n    return tgt_texts\n\n\nlen_idx = random.sample(list(df.index[(df.question1.str.len() < max_length) & (df.question2.str.len() < max_length)]), num_sentences)\nfor batch_idx in np.split(len_idx, np.arange(batch_size, len(len_idx), batch_size)):\n    df.loc[batch_idx, 'aug1'] = get_response(list(\"paraphrase: \" + df.loc[batch_idx, 'question1'] + \" </s>\"))\n    df.loc[batch_idx, 'aug2'] = get_response(list(\"paraphrase: \" + df.loc[batch_idx, 'question2'] + \" </s>\"))\n\naug_df = df[df.aug1.notnull()]\naug_df.to_csv('aug_train.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T10:03:25.802609Z","iopub.execute_input":"2022-04-22T10:03:25.803184Z","iopub.status.idle":"2022-04-22T10:03:25.809358Z","shell.execute_reply.started":"2022-04-22T10:03:25.803122Z","shell.execute_reply":"2022-04-22T10:03:25.808581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Labelling augmented dataset using cross-encoder model trained on Quora Question Pair dataset\naug_df = pd.read_csv('aug_train.csv')\nce_model = CrossEncoder('cross-encoder/stsb-distilroberta-base')\n\naug_df['q1a1'] = ce_model.predict(list(zip(aug_df['question1'], aug_df['aug1'])), batch_size=batch_size) > 0.5\naug_df['q1a2'] = ce_model.predict(list(zip(aug_df['question1'], aug_df['aug2'])), batch_size=batch_size) > 0.5\naug_df['q2a1'] = ce_model.predict(list(zip(aug_df['question2'], aug_df['aug1'])), batch_size=batch_size) > 0.5\naug_df['q2a2'] = ce_model.predict(list(zip(aug_df['question2'], aug_df['aug2'])), batch_size=batch_size) > 0.5\naug_df['a1a2'] = ce_model.predict(list(zip(aug_df['aug1'], aug_df['aug2'])), batch_size=batch_size) > 0.5\naug_df[['q1a1', 'q1a2', 'q2a1', 'q2a2', 'a1a2']] = aug_df[['q1a1', 'q1a2', 'q2a1', 'q2a2', 'a1a2']].astype(int)\n\nflat_df = pd.DataFrame.from_dict({'question1': pd.concat([aug_df.question1, aug_df.question1, aug_df.question2, aug_df.question2, aug_df.aug1], ignore_index=True),\n                            'question2': pd.concat([aug_df.aug1, aug_df.aug2, aug_df.aug1, aug_df.aug2, aug_df.aug2], ignore_index=True),\n                            'is_duplicate': pd.concat([aug_df.q1a1, aug_df.q1a2, aug_df.q2a1, aug_df.q2a2, aug_df.a1a2], ignore_index=True)})\nflat_df.to_csv('flat_train.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T10:03:25.810579Z","iopub.execute_input":"2022-04-22T10:03:25.810997Z","iopub.status.idle":"2022-04-22T10:03:25.819969Z","shell.execute_reply.started":"2022-04-22T10:03:25.810961Z","shell.execute_reply":"2022-04-22T10:03:25.81928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"flat_df.is_duplicate.groupby(flat_df.is_duplicate).count()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T10:03:25.82308Z","iopub.execute_input":"2022-04-22T10:03:25.823268Z","iopub.status.idle":"2022-04-22T10:03:25.83043Z","shell.execute_reply.started":"2022-04-22T10:03:25.82324Z","shell.execute_reply":"2022-04-22T10:03:25.829658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"silver_samples = []\nwith open('flat_train.csv', encoding='utf8') as fIn:\n    reader = csv.DictReader(fIn)\n    for row in reader:\n        sample = InputExample(texts=[row['question1'], row['question2']], label=int(row['is_duplicate']))\n        silver_samples.append(sample)\n        \ntrain_dataloader = DataLoader(gold_samples + silver_samples, shuffle=True, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T10:03:25.831843Z","iopub.execute_input":"2022-04-22T10:03:25.832309Z","iopub.status.idle":"2022-04-22T10:03:26.963249Z","shell.execute_reply.started":"2022-04-22T10:03:25.832276Z","shell.execute_reply":"2022-04-22T10:03:26.962503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dev_sentences1 = []\ndev_sentences2 = []\ndev_labels = []\nwith open(os.path.join('classification/dev_pairs.tsv'), encoding='utf8') as fIn:\n    reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_NONE)\n    for row in reader:\n        dev_sentences1.append(row['question1'])\n        dev_sentences2.append(row['question2'])\n        dev_labels.append(int(row['is_duplicate']))\n        \ndev_evaluator = evaluation.BinaryClassificationEvaluator(dev_sentences1, dev_sentences2, dev_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T10:03:26.964686Z","iopub.execute_input":"2022-04-22T10:03:26.964935Z","iopub.status.idle":"2022-04-22T10:03:27.285775Z","shell.execute_reply.started":"2022-04-22T10:03:26.964902Z","shell.execute_reply":"2022-04-22T10:03:27.285034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_sentences1 = []\ntest_sentences2 = []\ntest_labels = []\nwith open(\"classification/test_pairs.tsv\", encoding='utf8') as fIn:\n    reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_NONE)\n    for row in reader:\n        test_sentences1.append(row['question1'])\n        test_sentences2.append(row['question2'])\n        test_labels.append(int(row['is_duplicate']))\n        \nevaluator = evaluation.BinaryClassificationEvaluator(test_sentences1, test_sentences2, test_labels, \n                                                     batch_size=batch_size, \n                                                     write_csv=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T10:03:27.286913Z","iopub.execute_input":"2022-04-22T10:03:27.287168Z","iopub.status.idle":"2022-04-22T10:03:27.961083Z","shell.execute_reply.started":"2022-04-22T10:03:27.287131Z","shell.execute_reply":"2022-04-22T10:03:27.960326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_embedding_model = models.Transformer('distilbert-base-uncased', max_seq_length=256)\npooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n                               pooling_mode_mean_tokens=True,\n                               pooling_mode_cls_token=False,\n                               pooling_mode_max_tokens=False)\nbi_encoder = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n\n# for training old model\n# bi_encoder = SentenceTransformer('../input/aug-sbert-stsb/output/sbert_stsb_5')","metadata":{"execution":{"iopub.status.busy":"2022-04-22T10:03:27.962266Z","iopub.execute_input":"2022-04-22T10:03:27.962539Z","iopub.status.idle":"2022-04-22T10:03:36.739906Z","shell.execute_reply.started":"2022-04-22T10:03:27.96249Z","shell.execute_reply":"2022-04-22T10:03:36.739184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"margin = 0.5\ndistance_metric = losses.SiameseDistanceMetric.COSINE_DISTANCE\ntrain_loss = losses.OnlineContrastiveLoss(model=bi_encoder, distance_metric=distance_metric, margin=margin)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T10:03:36.741297Z","iopub.execute_input":"2022-04-22T10:03:36.741546Z","iopub.status.idle":"2022-04-22T10:03:36.748328Z","shell.execute_reply.started":"2022-04-22T10:03:36.741497Z","shell.execute_reply":"2022-04-22T10:03:36.747693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bi_encoder.fit(train_objectives=[(train_dataloader, train_loss)], \n               evaluator=dev_evaluator, \n               epochs=num_epochs, \n               output_path=model_save_path, \n               save_best_model=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T10:04:59.973842Z","iopub.execute_input":"2022-04-22T10:04:59.974174Z","iopub.status.idle":"2022-04-22T10:06:20.355038Z","shell.execute_reply.started":"2022-04-22T10:04:59.974137Z","shell.execute_reply":"2022-04-22T10:06:20.351223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# saving evaluation scores\nbi_encoder.evaluate(evaluator, output_path='.')","metadata":{"execution":{"iopub.status.busy":"2022-04-22T10:06:20.359616Z","iopub.status.idle":"2022-04-22T10:06:20.362594Z","shell.execute_reply.started":"2022-04-22T10:06:20.362158Z","shell.execute_reply":"2022-04-22T10:06:20.362188Z"},"trusted":true},"execution_count":null,"outputs":[]}]}