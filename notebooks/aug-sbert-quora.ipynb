{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --quiet -U sentence-transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-21T08:22:53.233955Z","iopub.execute_input":"2022-04-21T08:22:53.234269Z","iopub.status.idle":"2022-04-21T08:23:52.336248Z","shell.execute_reply.started":"2022-04-21T08:22:53.234189Z","shell.execute_reply":"2022-04-21T08:23:52.33542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Dowloading split dataset\n! wget https://public.ukp.informatik.tu-darmstadt.de/reimers/sentence-transformers/datasets/quora-IR-dataset.zip\n! unzip ./quora-IR-dataset.zip","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:23:59.023689Z","iopub.execute_input":"2022-04-21T08:23:59.023965Z","iopub.status.idle":"2022-04-21T08:24:11.681386Z","shell.execute_reply.started":"2022-04-21T08:23:59.023937Z","shell.execute_reply":"2022-04-21T08:24:11.680559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom datetime import datetime\nimport csv\nimport random\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader\nfrom sentence_transformers import models, losses, util\nfrom sentence_transformers import SentenceTransformer, evaluation\nfrom sentence_transformers.readers import InputExample\nfrom transformers import T5ForConditionalGeneration,T5Tokenizer\nfrom sentence_transformers.cross_encoder import CrossEncoder\n\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n\n\n# setting seed\nrandom.seed(42)\nos.environ['PYTHONHASHSEED'] = str(42)\nnp.random.seed(42)\ntorch.manual_seed(42)\ntorch.cuda.manual_seed(42)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = True","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:24:11.683849Z","iopub.execute_input":"2022-04-21T08:24:11.684328Z","iopub.status.idle":"2022-04-21T08:24:18.683583Z","shell.execute_reply.started":"2022-04-21T08:24:11.684277Z","shell.execute_reply":"2022-04-21T08:24:18.682725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 5\nbatch_size = 32\nmodel_save_path = 'output/sbert_custom_10'","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:24:18.685024Z","iopub.execute_input":"2022-04-21T08:24:18.68527Z","iopub.status.idle":"2022-04-21T08:24:18.690301Z","shell.execute_reply.started":"2022-04-21T08:24:18.685236Z","shell.execute_reply":"2022-04-21T08:24:18.688971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gold_samples = []\nwith open('classification/train_pairs.tsv', encoding='utf8') as fIn:\n    reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_NONE)\n    for row in reader:\n        sample = InputExample(texts=[row['question1'], row['question2']], label=int(row['is_duplicate']))\n        gold_samples.append(sample)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:24:18.692784Z","iopub.execute_input":"2022-04-21T08:24:18.693405Z","iopub.status.idle":"2022-04-21T08:24:22.320522Z","shell.execute_reply.started":"2022-04-21T08:24:18.693365Z","shell.execute_reply":"2022-04-21T08:24:22.31973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('./classification/train_pairs.tsv', delimiter='\\t', on_bad_lines='skip')\ndf","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:24:22.321838Z","iopub.execute_input":"2022-04-21T08:24:22.322108Z","iopub.status.idle":"2022-04-21T08:24:22.328338Z","shell.execute_reply.started":"2022-04-21T08:24:22.322074Z","shell.execute_reply":"2022-04-21T08:24:22.327635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.is_duplicate.groupby(df.is_duplicate).count()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:24:22.329626Z","iopub.execute_input":"2022-04-21T08:24:22.32987Z","iopub.status.idle":"2022-04-21T08:24:22.499471Z","shell.execute_reply.started":"2022-04-21T08:24:22.329837Z","shell.execute_reply":"2022-04-21T08:24:22.498679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Paraphrase sentences to generated new dataset using T5 model trained on duplicate questions from the Quora dataset. \n# Pre-trained model available at https://huggingface.co/ramsrigouthamg/t5_paraphraser\n\nnum_sentences = 20000 # number of rows used to generate augmented data\nmax_length = 256 - len(\"paraphrase: \" + \" </s>\")    \n\nmodel_name = 'ramsrigouthamg/t5_paraphraser'\ntorch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\ntokenizer = T5Tokenizer.from_pretrained(model_name)\nmodel = T5ForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n\ndef get_response(input_texts, num_return_sequences=1):\n    encoding = tokenizer.batch_encode_plus(input_texts,pad_to_max_length=True, return_tensors=\"pt\", max_length=256)\n    input_ids, attention_masks = encoding[\"input_ids\"].to(torch_device), encoding[\"attention_mask\"].to(torch_device)\n    beam_outputs = model.generate(\n        input_ids=input_ids, attention_mask=attention_masks,\n        do_sample=True,\n        max_length=max_length,\n        top_k=120,\n        top_p=0.98,\n        early_stopping=True,\n        num_return_sequences=num_return_sequences\n    )\n    tgt_texts = tokenizer.batch_decode(beam_outputs, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n    return tgt_texts\n\n\nlen_idx = random.sample(list(df.index[(df.question1.str.len() < max_length) & (df.question2.str.len() < max_length)]), num_sentences)\nfor batch_idx in np.split(len_idx, np.arange(batch_size, len(len_idx), batch_size)):\n    df.loc[batch_idx, 'aug1'] = get_response(list(\"paraphrase: \" + df.loc[batch_idx, 'question1'] + \" </s>\"))\n    df.loc[batch_idx, 'aug2'] = get_response(list(\"paraphrase: \" + df.loc[batch_idx, 'question2'] + \" </s>\"))\n\naug_df = df[df.aug1.notnull()]\naug_df.to_csv('aug_train.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:24:22.500595Z","iopub.execute_input":"2022-04-21T08:24:22.503434Z","iopub.status.idle":"2022-04-21T08:24:22.509384Z","shell.execute_reply.started":"2022-04-21T08:24:22.503394Z","shell.execute_reply":"2022-04-21T08:24:22.508669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Labelling augmented dataset using cross-encoder model trained on Quora Question Pair dataset\naug_df = pd.read_csv('aug_train.csv')\nce_model = CrossEncoder('cross-encoder/quora-distilroberta-base')\n\naug_df['q1a1'] = ce_model.predict(list(zip(aug_df['question1'], aug_df['aug1'])), batch_size=batch_size) > 0.5\naug_df['q1a2'] = ce_model.predict(list(zip(aug_df['question1'], aug_df['aug2'])), batch_size=batch_size) > 0.5\naug_df['q2a1'] = ce_model.predict(list(zip(aug_df['question2'], aug_df['aug1'])), batch_size=batch_size) > 0.5\naug_df['q2a2'] = ce_model.predict(list(zip(aug_df['question2'], aug_df['aug2'])), batch_size=batch_size) > 0.5\naug_df['a1a2'] = ce_model.predict(list(zip(aug_df['aug1'], aug_df['aug2'])), batch_size=batch_size) > 0.5\naug_df[['q1a1', 'q1a2', 'q2a1', 'q2a2', 'a1a2']] = aug_df[['q1a1', 'q1a2', 'q2a1', 'q2a2', 'a1a2']].astype(int)\n\nflat_df = pd.DataFrame.from_dict({'question1': pd.concat([aug_df.question1, aug_df.question1, aug_df.question2, aug_df.question2, aug_df.aug1], ignore_index=True),\n                            'question2': pd.concat([aug_df.aug1, aug_df.aug2, aug_df.aug1, aug_df.aug2, aug_df.aug2], ignore_index=True),\n                            'is_duplicate': pd.concat([aug_df.q1a1, aug_df.q1a2, aug_df.q2a1, aug_df.q2a2, aug_df.a1a2], ignore_index=True)})\nflat_df.to_csv('flat_train.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:24:22.511122Z","iopub.execute_input":"2022-04-21T08:24:22.511806Z","iopub.status.idle":"2022-04-21T08:24:22.519985Z","shell.execute_reply.started":"2022-04-21T08:24:22.511766Z","shell.execute_reply":"2022-04-21T08:24:22.519261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"flat_df.is_duplicate.groupby(flat_df.is_duplicate).count()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:24:22.521484Z","iopub.execute_input":"2022-04-21T08:24:22.521814Z","iopub.status.idle":"2022-04-21T08:24:22.533011Z","shell.execute_reply.started":"2022-04-21T08:24:22.521779Z","shell.execute_reply":"2022-04-21T08:24:22.532193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"silver_samples = []\nwith open('flat_train.csv', encoding='utf8') as fIn:\n    reader = csv.DictReader(fIn)\n    for row in reader:\n        sample = InputExample(texts=[row['question1'], row['question2']], label=int(row['is_duplicate']))\n        silver_samples.append(sample)\n        \ntrain_dataloader = DataLoader(gold_samples + silver_samples, shuffle=True, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:24:22.53591Z","iopub.execute_input":"2022-04-21T08:24:22.536528Z","iopub.status.idle":"2022-04-21T08:24:23.643009Z","shell.execute_reply.started":"2022-04-21T08:24:22.536433Z","shell.execute_reply":"2022-04-21T08:24:23.64226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dev_sentences1 = []\ndev_sentences2 = []\ndev_labels = []\nwith open(os.path.join('classification/dev_pairs.tsv'), encoding='utf8') as fIn:\n    reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_NONE)\n    for row in reader:\n        dev_sentences1.append(row['question1'])\n        dev_sentences2.append(row['question2'])\n        dev_labels.append(int(row['is_duplicate']))\n        \ndev_evaluator = evaluation.BinaryClassificationEvaluator(dev_sentences1, dev_sentences2, dev_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:24:23.644385Z","iopub.execute_input":"2022-04-21T08:24:23.644643Z","iopub.status.idle":"2022-04-21T08:24:23.989223Z","shell.execute_reply.started":"2022-04-21T08:24:23.644607Z","shell.execute_reply":"2022-04-21T08:24:23.98848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_sentences1 = []\ntest_sentences2 = []\ntest_labels = []\nwith open(\"classification/test_pairs.tsv\", encoding='utf8') as fIn:\n    reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_NONE)\n    for row in reader:\n        test_sentences1.append(row['question1'])\n        test_sentences2.append(row['question2'])\n        test_labels.append(int(row['is_duplicate']))\n        \nevaluator = evaluation.BinaryClassificationEvaluator(test_sentences1, test_sentences2, test_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:24:23.990636Z","iopub.execute_input":"2022-04-21T08:24:23.99086Z","iopub.status.idle":"2022-04-21T08:24:24.64401Z","shell.execute_reply.started":"2022-04-21T08:24:23.990829Z","shell.execute_reply":"2022-04-21T08:24:24.643297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_embedding_model = models.Transformer('distilbert-base-uncased', max_seq_length=256)\npooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n                               pooling_mode_mean_tokens=True,\n                               pooling_mode_cls_token=False,\n                               pooling_mode_max_tokens=False)\nbi_encoder = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n\n# for loading old model\n# bi_encoder = SentenceTransformer('../input/aug-sbert-quora/output/sbert_quora_5')","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:24:24.645244Z","iopub.execute_input":"2022-04-21T08:24:24.645512Z","iopub.status.idle":"2022-04-21T08:24:27.870809Z","shell.execute_reply.started":"2022-04-21T08:24:24.645479Z","shell.execute_reply":"2022-04-21T08:24:27.870086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"margin = 0.5\ndistance_metric = losses.SiameseDistanceMetric.COSINE_DISTANCE\ntrain_loss = losses.OnlineContrastiveLoss(model=bi_encoder, distance_metric=distance_metric, margin=margin)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bi_encoder.fit(train_objectives=[(train_dataloader, train_loss)], \n               evaluator=dev_evaluator, \n               epochs=num_epochs, \n               output_path=model_save_path, \n               save_best_model=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:25:49.985757Z","iopub.execute_input":"2022-04-21T08:25:49.986023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# saving evaluation results\nbi_encoder.evaluate(evaluator, output_path='.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}